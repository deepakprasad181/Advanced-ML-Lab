import numpy as np

def sigmoid(x):
    return 1 / (1 + np.exp(-x))

def sigmoid_derivative(x):
    return x * (1 - x)

X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])
y = np.array([[0], [1], [1], [0]])

i_s, hs, os = 2, 4, 1

lr, epochs = 0.1, 10000

np.random.seed(1)
hw = np.random.uniform(size=(i_s, hs))
hb = np.zeros((1, hs))
ow = np.random.uniform(size=(hs, os))
ob = np.zeros((1, os))

for epoch in range(epochs):
    # Forward pass
    hlo = sigmoid(np.dot(X, hw) + hb)
    olo = sigmoid(np.dot(hlo, ow) + ob)

    # Backpropagation
    d_output = (y - olo) * sigmoid_derivative(olo)
    d_hidden = d_output.dot(ow.T) * sigmoid_derivative(hlo)

    # Update weights and biases
    ow += hlo.T.dot(d_output) * lr
    ob += np.sum(d_output, axis=0, keepdims=True) * lr
    hw += X.T.dot(d_hidden) * lr
    hb += np.sum(d_hidden, axis=0, keepdims=True) * lr

# Testing
hlo = sigmoid(np.dot(X, hw) + hb)
olo = sigmoid(np.dot(hlo, ow) + ob)

print("Predicted Output:")
print(olo)
